# OPEA Configuration
OPEA_MODEL_PATH=./models/Meta-Llama-3.2-3B-Instruct-Q6_K_L.gguf
OPEA_MODEL_NAME=Meta-Llama-3.2:3B  # Default model name

# GPU Configuration
CUDA_VISIBLE_DEVICES=0  # Specify which GPU to use
GPU_MEMORY_UTILIZATION=0.9  # Maximum GPU memory utilization (0.0-1.0)

# Application Settings
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_HEADLESS=true
STREAMLIT_BROWSER_GATHER_USAGE_STATS=false

# Logging Configuration
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
